{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A tensor can have a single value or value with multiple dimensions.\n",
    "- An easy way of finding the dimensions of a tensor is basically counting the number of square brackets at the start.\n",
    "- The term tensor is so general. With a tensor many values with many dimensions can be represented.\n",
    "- Everything under this is also a tensor just with special names.\n",
    "\n",
    "- Default dtype of a tensor is float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scalar means, has only one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(77)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a scalar value\n",
    "scalar = torch.tensor(77)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A scalar value has only a magnitude like 77 and has no directlion. Hence a scalar value is 0 dimensional.\n"
     ]
    }
   ],
   "source": [
    "print(f\"A scalar value has only a magnitude like {scalar.item()} and has no directlion. Hence a scalar value is {scalar.ndim} dimensional.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector means has arbitrary values in single dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([0, 2, 4, 6])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions of vector: 1\n",
      "Size of the vector: torch.Size([4])\n",
      "The vector has 4 elements.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The term vector is used for an auto growing array in programming generally.\n",
    "# In physics a vector is a structure representing a magnitude and a direction.\n",
    "# In above, a row vector has created.\n",
    "print(f\"\"\"\n",
    "Dimensions of vector: {vector.ndim}\n",
    "Size of the vector: {vector.shape}\n",
    "The vector has {vector.shape[0]} elements.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix has at least 2 dimensions like a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2D = torch.tensor([[1, 2],\n",
    "                         [3, 4]])\n",
    "matrix2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2D.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix of matrices are called a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10, 11],\n",
       "         [12, 13],\n",
       "         [14, 15]]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[[10, 11],\n",
    "                        [12, 13],\n",
    "                        [14, 15],]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15]])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  index 1 is out of bounds for dimension 0 with size 1\n"
     ]
    }
   ],
   "source": [
    "# Will give error because only one table is initialized.\n",
    "# Think it about like rubix cube.\n",
    "try:\n",
    "    tensor[1]\n",
    "except Exception as e:\n",
    "    print(\"Error: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![uninitialized_tensor.png](resources/uninitialized_tensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10, 11],\n",
       "         [12, 13],\n",
       "         [14, 15]],\n",
       "\n",
       "        [[20, 21],\n",
       "         [22, 23],\n",
       "         [24, 25]]])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[[10, 11],\n",
    "                        [12, 13],\n",
    "                        [14, 15],],\n",
    "                       [[20, 21],\n",
    "                        [22, 23],\n",
    "                        [24, 25],]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new ndim: 3\n",
      "new shape torch.Size([2, 3, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "new ndim: {tensor.ndim}\n",
    "new shape {tensor.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 21],\n",
       "        [22, 23],\n",
       "        [24, 25]])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  expected sequence of length 2 at dim 1 (got 1)\n"
     ]
    }
   ],
   "source": [
    "# Tensors must have matching dimensions.\n",
    "try:\n",
    "\n",
    "    jagged_tensor = torch.tensor([[1, 2],\n",
    "\n",
    "                                  [3]])\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3071, 0.1858],\n",
       "        [0.2459, 0.0641],\n",
       "        [0.0534, 0.8998]])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(3,2))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor of Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros(size=(5, 5))\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor of Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor = torch.ones(size=(2, 2))\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Tensor in Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start inclusive, end exclusive: [start, end)\n",
    "range_tensor = torch.arange(start=1, end=10)\n",
    "range_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_tensor = torch.arange(start=0, end=10, step=2)\n",
    "even_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a tensor in the same shape of input tensor\n",
    "zeros_like_tensor = torch.zeros_like(input=range_tensor)\n",
    "zeros_like_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Tensor Parameters\n",
    "\n",
    "1. [Tensor dtype](https://pytorch.org/docs/stable/tensors.html#data-types) (eg. float32 - single precision, float16 - half precision)\n",
    "2. Tensor device (CPU or GPU)\n",
    "3. Tensor gradient (should pytorch watch the values inside)\n",
    "\n",
    "---\n",
    "\n",
    "- The default dtype is float32 but if not specified dtype will be automatically inferred. If all data is integer values, dtype will be int64.\n",
    "\n",
    "- If an operation performed between a tensor lives in GPU and other in memory (RAM), an error will occur.\n",
    "\n",
    "- If tensor shapes do not match for different operations' requirements, an error will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 0, 3])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_tensor = torch.tensor(data=[1, 9, 0, 3],\n",
    "                             dtype=None,\n",
    "                             device=None,\n",
    "                             requires_grad=False)\n",
    "params_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 9., 0., 3.])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor = torch.tensor(data=[1, 9, 0, 3],\n",
    "                              dtype=torch.float32)\n",
    "float32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor is neighbour with OS.\n"
     ]
    }
   ],
   "source": [
    "if float32_tensor.is_cuda:\n",
    "    print(\"Tensor living peacefully in GPU.\")\n",
    "else:\n",
    "    print(\"Tensor is neighbour with OS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 9., 0., 3.], dtype=torch.float16)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor = torch.tensor(data=[1, 9, 0, 3],\n",
    "                              dtype=torch.float16)\n",
    "float16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors? Huh..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = float16_tensor * float32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., 81.,  0.,  9.])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Manipulation\n",
    "\n",
    "- Supported basic operations like adding, subtracting, element-wise multiplying, division and matrix multiplication.\n",
    "- Besides matrix multipilcation with dot product, all operations made element-wise.\n",
    "- Operations return a new tensor. Original tensor is not touched.\n",
    "\n",
    "- Normal operands are accepted. But PyTorch also has built-in methods for tensor operations.\n",
    "- Operations can be made with constants or tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_tensor = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 8])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_tensor + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 16, 24])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_tensor * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.0000, 1.5000])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_tensor / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 8])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(op_tensor, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(op_tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 16, 24])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(op_tensor, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 1.0000, 1.5000])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(op_tensor, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.6667, 0.8000])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another tensor\n",
    "tensor_A = torch.tensor([0, 2, 4])\n",
    "tensor_B = torch.tensor([1, 3, 5])\n",
    "\n",
    "torch.div(tensor_A, tensor_B)  # tensor([0, 6, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "Rules:\n",
    "1. Inner dimensions should be the same.\n",
    "\n",
    "`(5, 2) @ (3, 12)` -> won't work\n",
    "\n",
    "`(5, 2) @ (2, 12)` -> will work\n",
    "\n",
    "2. Multiplication result will have the shape of outer dimensions.\n",
    "\n",
    "`(5,2) @ (2, 12)` -> `(5, 12)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul_tensor = torch.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(331.0392)\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val = 0\n",
    "for i in range(len(matmul_tensor)):\n",
    "    val += matmul_tensor[i] * matmul_tensor[i]\n",
    "\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(331.0391)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(torch.matmul(matmul_tensor, matmul_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\n"
     ]
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]])\n",
    "\n",
    "try:\n",
    "    torch.matmul(tensor_A, tensor_B)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor_B = torch.tensor([[7, 8, 9],\n",
    "                             [10, 11, 12]])\n",
    "\n",
    "torch.matmul(tensor_A, new_tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose of a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "tensor_B shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_B.T)\n",
    "print(\"tensor_B shape:\", tensor_B.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor shape of A: torch.Size([3, 2])\n",
      "Tensor shape of B: torch.Size([3, 2])\n",
      "Tensor shape of transposed A: torch.Size([2, 3]) \n",
      "Tensor shape of transposed B: torch.Size([2, 3])\n",
      "Tensor shape of A and B matrix multiplied torch.Size([3, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Tensor shape of A: {tensor_A.shape}\n",
    "Tensor shape of B: {tensor_B.shape}\n",
    "Tensor shape of transposed A: {tensor_A.T.shape} \n",
    "Tensor shape of transposed B: {tensor_B.T.shape}\n",
    "Tensor shape of A and B matrix multiplied {torch.matmul(tensor_A, tensor_B.T).shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Aggregation\n",
    "\n",
    "- Finding the min, max, mean, sum..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.int64)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_tensor = torch.arange(1, 10)\n",
    "agg_tensor, agg_tensor.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1))"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either use tensor function directly or use torch function and pass the tensor\n",
    "agg_tensor.min(), torch.min(agg_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_tensor.max(), torch.max(agg_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long\n"
     ]
    }
   ],
   "source": [
    "# Mean excepts a float or complex number input\n",
    "# https://pytorch.org/docs/stable/generated/torch.mean.html\n",
    "try:\n",
    "    agg_tensor.mean()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With tensor method:  tensor(5.)\n",
      "With tensor method but input casted before: tensor(5.)\n",
      "With torch methods:  tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "# Either use optional dtype parameter to specify both dtype of returned tensor\n",
    "# and cast input tensor before operation\n",
    "print(\"With tensor method: \", agg_tensor.mean(dtype=torch.float32))\n",
    "\n",
    "# Or cast it before using if not sure.\n",
    "print(\"With tensor method but input casted before:\", \n",
    "      agg_tensor.type(torch.float32).mean())\n",
    "\n",
    "# Similar to min and max, mean can be calculated with torch methods.\n",
    "# Beware that input tensor still needed to be casted to suppoted dtype.\n",
    "print(\"With torch methods: \", torch.mean(agg_tensor.type(torch.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45), tensor(45))"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_tensor.sum(), torch.sum(agg_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arg Min\n",
    "\n",
    "Index of minimum element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_tensor.argmin(), torch.argmin(agg_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Minimum value in tensor is 1 \n",
      "and index of it is 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Totally unnecessary but here it is anyway.\n",
    "print(f\"\"\"\n",
    "Minimum value in tensor is {agg_tensor[agg_tensor.argmin()]} \n",
    "and index of it is {agg_tensor.argmin()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arg Max\n",
    "\n",
    "Index of maximum element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8), tensor(8))"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_tensor.argmax(), torch.argmax(agg_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Shape Manipulation\n",
    "\n",
    "- Reshape: Reshape tensor to specified shape.\n",
    "- View: Using the same memory return a view of the tensor.\n",
    "- Stack: Stack tensor on top of each other (vertical stack) or side by side (horizonal stack). vstack and hstack also exists as seperate methods.\n",
    "- Squeeze: Removes the shape of `1` dimensions from tensor.\n",
    "- Unsqueeze: Adds a new dimension of `1` to specified tensor index.\n",
    "- Permute: Rearrange dimension order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]), torch.Size([12]))"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_tensor = torch.arange(1, 13)\n",
    "dummy_tensor, dummy_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape '[1, 10]' is invalid for input of size 12\n"
     ]
    }
   ],
   "source": [
    "# New shape must be compatible with old tensor's shape\n",
    "try:\n",
    "    reshaped_tensor = dummy_tensor.reshape(1, 10)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]]),\n",
       " torch.Size([1, 12]))"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor = dummy_tensor.reshape(1, 12)\n",
    "reshaped_tensor, reshaped_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1],\n",
       "         [ 2],\n",
       "         [ 3],\n",
       "         [ 4],\n",
       "         [ 5],\n",
       "         [ 6],\n",
       "         [ 7],\n",
       "         [ 8],\n",
       "         [ 9],\n",
       "         [10],\n",
       "         [11],\n",
       "         [12]]),\n",
       " torch.Size([12, 1]))"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It was a row vector but after reshaping turned into a column vector.\n",
    "reshaped_tensor = dummy_tensor.reshape(12, 1)\n",
    "reshaped_tensor, reshaped_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor = dummy_tensor.reshape(4, 3)\n",
    "reshaped_tensor, reshaped_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:  tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])  \n",
      "\n",
      "View tensor:  tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "+----------After altering-----------+\n",
      "View tensor:  tensor([[99,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "Original tensor:  tensor([99,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "# See the original tensor first\n",
    "print(\"Original tensor: \", dummy_tensor, \" \\n\")\n",
    "\n",
    "# Like reshape but shares the same memory\n",
    "view_tensor = dummy_tensor.view(3,4)\n",
    "print(\"View tensor: \", view_tensor)\n",
    "\n",
    "# Alter view tensor\n",
    "view_tensor[0, 0] = 99\n",
    "\n",
    "print(\"+----------After altering-----------+\")\n",
    "# Observe that altered index changed in original tensor too\n",
    "print(\"View tensor: \", view_tensor)\n",
    "print(\"Original tensor: \", dummy_tensor)\n",
    "\n",
    "# Revert original tensor to initial state for future use.\n",
    "dummy_tensor = torch.arange(1, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack\n",
    "\n",
    "- Tensors should be same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_tensor = torch.stack([dummy_tensor, dummy_tensor], dim=0)\n",
    "stacked_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1],\n",
       "        [ 2,  2],\n",
       "        [ 3,  3],\n",
       "        [ 4,  4],\n",
       "        [ 5,  5],\n",
       "        [ 6,  6],\n",
       "        [ 7,  7],\n",
       "        [ 8,  8],\n",
       "        [ 9,  9],\n",
       "        [10, 10],\n",
       "        [11, 11],\n",
       "        [12, 12]])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_tensor = torch.stack([dummy_tensor, dummy_tensor], dim=1)\n",
    "stacked_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/docs/main/generated/torch.stack.html\n",
    "# Funnily enough, website states that dim parameter has to be between 0 and \n",
    "# the number of dimensions of concatenated tensors (inclusive).\n",
    "# But -1 works like 1 and -2 works like 0 because of counting backwards like python slices.\n",
    "try:\n",
    "    stacked_tensor = torch.stack([dummy_tensor, dummy_tensor, dummy_tensor], dim=2)\n",
    "    print(stacked_tensor)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hstack\n",
    "\n",
    "- hstack method concatenates the inputs side by side depending on the written order. If row counts of tensors are equal, all's good with the world.\n",
    "- If two tensors are vectors, next one will be appended to the previous tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[ 5,  6,  7],\n",
      "        [ 8,  9, 10]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  5,  6,  7],\n",
       "        [ 3,  4,  8,  9, 10]])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hstack_dummy = torch.arange(1, 5)\n",
    "\n",
    "hstack_mat_A = torch.arange(1, 5).reshape((2,2))\n",
    "hstack_mat_B = torch.arange(5, 11).reshape((2,3)) # this works\n",
    "#hstack_mat_B = torch.arange(5, 11).reshape((3,2)) # this won't work\n",
    "\n",
    "print(hstack_mat_A)\n",
    "print(hstack_mat_B)\n",
    "\n",
    "torch.hstack([hstack_mat_A, hstack_mat_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "Tensor B: tensor([[[ 9, 10],\n",
      "         [11, 12]],\n",
      "\n",
      "        [[13, 14],\n",
      "         [15, 16]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4],\n",
       "         [ 9, 10],\n",
       "         [11, 12]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 7,  8],\n",
       "         [13, 14],\n",
       "         [15, 16]]])"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hstack_tensor_A = torch.arange(1, 9).reshape((2, 2, 2))\n",
    "hstack_tensor_B = torch.arange(9, 17).reshape((2, 2, 2))\n",
    "\n",
    "print(\"Tensor A:\", hstack_tensor_A)\n",
    "print(\"Tensor B:\", hstack_tensor_B)\n",
    "\n",
    "torch.hstack([hstack_tensor_A, hstack_tensor_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hstack_logic.png](resources/hstack_logic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vstack\n",
    "\n",
    "This one does not have much of an appeal. Same with stack(dim=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.vstack([dummy_tensor, dummy_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueezed: 2 depth, 3 columns, 1 row\n",
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]))"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's weird...\n",
    "# But if you have a tensor of shape (1, 224, 224, 3) but just (224, 224, 3) required,\n",
    "# Just squeeze it.\n",
    "# Also supports removing from specified dimensions using tuple or int if single dim be removed\n",
    "\n",
    "sq_tensor = torch.zeros((2, 3, 1)) # depth, col, row\n",
    "print(\"Unsqueezed: 2 depth, 3 columns, 1 row\")\n",
    "#       +---+\n",
    "#      /   /|\n",
    "#     +---+ |                           +---+---+---+\n",
    "#    /   /| +                          /   /   /   /|\n",
    "#   +---+ |/|                         +---+---+---+ |\n",
    "#   |   | + |              \\          |   |   |   | +\n",
    "#   |   |/| +         ------\\         |   |   |   |/|\n",
    "#   +---+ |/|         ------/         +---+---+---+ |\n",
    "#   |   | + |              /          |   |   |   | + \n",
    "#   |   |/| +                         |   |   |   |/\n",
    "#   +---+ |/                          +---+---+---+\n",
    "#   |   | +   \n",
    "#   |   |/    \n",
    "#   +---+    \n",
    "\n",
    "print(sq_tensor)\n",
    "sq_tensor.squeeze(), torch.squeeze(sq_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usq_tensor = torch.arange(1, 10)\n",
    "usq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of tensor before unsqueezing: torch.Size([9])\n",
      "Shape of tensor after unsqueezing for index 0: torch.Size([1, 9])\n",
      "Shape of tensor after unsqueezing for index 1: torch.Size([9, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Shape of tensor before unsqueezing: {usq_tensor.shape}\n",
    "Shape of tensor after unsqueezing for index 0: {usq_tensor.unsqueeze(dim=0).shape}\n",
    "Shape of tensor after unsqueezing for index 1: {usq_tensor.unsqueeze(dim=1).shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image is currently in order of width, height, color channels with the size of torch.Size([128, 128, 3])\n",
      "Image rearranged as color chanels, width, height. New shape is torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "#                           0    1   2\n",
    "image_tensor = torch.rand((128, 128, 3))\n",
    "print(\"Image is currently in order of width, height, color channels with the size of\", image_tensor.shape)\n",
    "\n",
    "rearranged_tensor = torch.permute(image_tensor, dims=(2, 1, 0)) # 2->0, 1->1, 0->2\n",
    "print(\"Image rearranged as color chanels, width, height. New shape is\", rearranged_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_tensor before changing permuted tensor: tensor(0.7146)\n",
      "image_tensor after changing permuted tensor: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Changes on assigned variable will effect original tensor since permute works as view.\n",
    "print(\"image_tensor before changing permuted tensor:\", image_tensor[0, 0, 0])\n",
    "rearranged_tensor[0, 0, 0] = 1\n",
    "\n",
    "print(\"image_tensor after changing permuted tensor:\", image_tensor[0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Indexing\n",
    "\n",
    "Tensors can be sliced like python arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_tensor = torch.arange(1, 10).reshape(1, 3, 3) # same as 2d matrix layout but in 3d.\n",
    "\n",
    "slice_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 is out of bounds for dimension 0 with size 1\n"
     ]
    }
   ],
   "source": [
    "# Will give an error because first dimension has only rank of 1 \n",
    "# and starting from 0.\n",
    "try:\n",
    "    slice_tensor[1]\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Give me 0th dimension of all values.\"\n",
    "slice_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Give me 0th dimension of all values.\"\n",
    "slice_tensor[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Give me first element of all dimensions\"\n",
    "# Utimately leads to retrieving first ever value in tensor.\n",
    "slice_tensor[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Give me the last element of a 3x3 tensor.\"\n",
    "slice_tensor[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Give me all values in 3rd column.\"\n",
    "slice_tensor[0, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch, Numpy and You\n",
    "\n",
    "PyTorch does not strictly depend on [Numpy](https://numpy.org/) but they can work together. Numpy is a widely used library in deep learning because of its speed and built-in functions. Also numpy array can be saved to a file for faster read-write operations from disk.\n",
    "\n",
    "![pytorch_and_numpy.png](resources/pytorch_and_numpy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64))"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float array to float tensor\n",
    "nparray = np.arange(1.0, 10.0)\n",
    "tensor_from_np = torch.from_numpy(nparray)\n",
    "\n",
    "nparray, tensor_from_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newly crated tensor from numpy array has dtype of float64 because numpy has default dtype of float 64. This is different than PyTorch's float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparray.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also numpy has different default integer dtype (int32). On the other hand PyTorch using int64 for integer tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32))"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Int array to int tensor\n",
    "nparray = np.arange(1, 10)\n",
    "tensor_from_np = torch.from_numpy(nparray)\n",
    "\n",
    "nparray, tensor_from_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 1).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure of dtypes\n",
    "np_array = np.arange(10., dtype=np.float32)\n",
    "np_tensor = torch.from_numpy(np_array)\n",
    "\n",
    "np_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Numpy array and tensor values share the same memory](https://pytorch.org/docs/2.5/generated/torch.from_numpy.html). Changes to either of the array of the tensor will be reflected to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([100., 200.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.],\n",
       "       dtype=float32),\n",
       " tensor([100., 200.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.]))"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array[0] = 100\n",
    "np_tensor[1] = 200\n",
    "\n",
    "np_array, np_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** If dtype changed after using ndarray for tensor creation, numpy array and tensor would no longer share the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.   1.   2.   3.   4.   5.   6.   7.   8.   9.] float64\n",
      "tensor([  0., 200.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "np_array = np.arange(10.)\n",
    "np_tensor = torch.from_numpy(np_array).type(torch.float32)\n",
    "\n",
    "np_array[0] = 100\n",
    "np_tensor[1] = 200\n",
    "\n",
    "print(np_array, np_array.dtype)\n",
    "print(np_tensor, np_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soon_to_array_tensor = torch.tensor([1, 2, 3])\n",
    "now_array_tensor = soon_to_array_tensor.numpy()\n",
    "\n",
    "now_array_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like pytorch infers dtype of numpy array and returns a tensor with same dtype, same applies if a tensor gets converted to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, dtype('int64'))"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soon_to_array_tensor.dtype, now_array_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to `tensor->numpy` array if tensor gets manipulated? Same as `numpy->tensor` they share the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 3, 4]), array([2, 3, 4], dtype=int64))"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soon_to_array_tensor += 1\n",
    "\n",
    "soon_to_array_tensor, now_array_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "\n",
    "- Every time a random number generating method called, a pseudorandom number generator is called.\n",
    "- In order to have reproducible results across the runs a random number seed can be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1395, 0.6975, 0.7881],\n",
      "        [0.9431, 0.2720, 0.2562],\n",
      "        [0.8427, 0.3948, 0.9350]])\n",
      "tensor([[0.8776, 0.4167, 0.2465],\n",
      "        [0.3616, 0.5553, 0.9127],\n",
      "        [0.0781, 0.7647, 0.0883]])\n",
      "tensor([[False, False, False],\n",
      "        [False, False, False],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "rand_tensor_A = torch.rand((3,3))\n",
    "rand_tensor_B = torch.rand((3,3))\n",
    "\n",
    "print(rand_tensor_A)\n",
    "print(rand_tensor_B)\n",
    "print(rand_tensor_A == rand_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2919, 0.2857, 0.4021],\n",
      "        [0.4645, 0.9503, 0.2564],\n",
      "        [0.6645, 0.8609, 0.3538]])\n",
      "tensor([[0.2919, 0.2857, 0.4021],\n",
      "        [0.4645, 0.9503, 0.2564],\n",
      "        [0.6645, 0.8609, 0.3538]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(77)\n",
    "rand_tensor_C = torch.rand((3, 3))\n",
    "torch.manual_seed(77)\n",
    "rand_tensor_D = torch.rand((3, 3))\n",
    "\n",
    "print(rand_tensor_C)\n",
    "print(rand_tensor_D)\n",
    "print(rand_tensor_C == rand_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running PyTorch on GPU\n",
    "\n",
    "- Until this part all the tensors were stored in memory.\n",
    "- This notebook written in a local machine with NVidia GPU. For using the same setup refer [here](README.md#how-did-i-installed).\n",
    "- If you'll work on a cloud environment, make sure you have access to a GPU. \n",
    "- You can check the GPU in colab with `!nvidia-smi` command.\n",
    "\n",
    "- For best practices check [here](https://pytorch.org/docs/stable/notes/cuda.html#best-practices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running PyTorch device agnostic. Use GPU if available. If not use CPU for operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For multiple GPU setups\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Existing Tensor to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_tensor = torch.tensor([1,2,3])\n",
    "cpu_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_tensor = cpu_tensor.to(device)\n",
    "gpu_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some libraries can not access GPU memory to perform calculations. In that case tensor to be used should moved back to memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gpu_tensor.numpy()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "welcome_back_tensor = gpu_tensor.cpu().numpy()\n",
    "welcome_back_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
